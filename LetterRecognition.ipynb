{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7180ded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               2176      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 26)                1690      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12122 (47.35 KB)\n",
      "Trainable params: 12122 (47.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 1.4967 - accuracy: 0.5817\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.8365 - accuracy: 0.7569\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.6752 - accuracy: 0.8008\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.5677 - accuracy: 0.8255\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4903 - accuracy: 0.8526\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8637\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3966 - accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.8864\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8988\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3081 - accuracy: 0.9045\n",
      "Training time: 14.796123266220093 seconds\n",
      "Enter a set of 16 features (separated by commas): 5,9,5,7,6,6,11,7,3,7,3,9,2,7,5,11\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "Predicted class: ['R']\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prediction time: 0.06334066390991211 seconds\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction time: 0.14309167861938477 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tkinter as tk\n",
    "from tkinter import Label, StringVar, Button, Entry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load the dataset\n",
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "\n",
    "# Split features : Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Training time:\", training_time, \"seconds\")\n",
    "\n",
    "# Define the class mapping dictionary as a global variable\n",
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Get user input for prediction\n",
    "user_input = input(\"Enter a set of 16 features (separated by commas): \")\n",
    "user_input = np.array(user_input.split(','), dtype=float).reshape(1, -1)\n",
    "\n",
    "# Make prediction\n",
    "try:\n",
    "    prediction = model.predict(user_input)\n",
    "    predicted_class = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "except Exception as e:\n",
    "    print(\"Error occurred during prediction:\", e)\n",
    "    \n",
    "# Measure prediction time\n",
    "start_time = time.time()\n",
    "prediction = model.predict(user_input)\n",
    "end_time = time.time()\n",
    "prediction_time = end_time - start_time\n",
    "print(\"Prediction time:\", prediction_time, \"seconds\")\n",
    "\n",
    "\n",
    "\n",
    "# GUI\n",
    "def predict_letter():\n",
    "    user_input = entry.get()\n",
    "    user_input_list = [int(x) for x in user_input.split(',')]\n",
    "    new_data = np.array(user_input_list).reshape(1, -1)  # Define new_data here\n",
    "\n",
    "    # Measure prediction time\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(new_data)\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    predicted_letter = class_mapping[predicted_class]\n",
    "\n",
    "    # Update result_var with prediction result and time\n",
    "    result_var.set(f'The predicted class is: {predicted_class}, which corresponds to the letter: {predicted_letter}. Prediction time: {prediction_time:.2f} seconds')\n",
    "    print(\"Prediction time:\", prediction_time, \"seconds\")\n",
    "\n",
    "# Create the main GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Letter Prediction GUI\")\n",
    "\n",
    "# Entry for user input\n",
    "entry_label = Label(root, text=\"Enter values for the 16 features separated by commas:\")\n",
    "entry_label.pack(pady=10)\n",
    "\n",
    "entry = Entry(root, width=50)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# Prediction button\n",
    "predict_button = Button(root, text=\"Predict Letter\", command=predict_letter)\n",
    "predict_button.pack(pady=10)\n",
    "\n",
    "# Result label\n",
    "result_var = StringVar()\n",
    "result_label = Label(root, textvariable=result_var)\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d134ad81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
